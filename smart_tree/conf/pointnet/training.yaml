# @package: _global_

wandb:
  project: tree
  entity: harry1576
  mode: disabled

fp16: True
num_epoch: 500
lr_decay: True
lr: 0.01
early_stop_epoch: 20
early_stop: True
capture_output: 1

batch_size: 16
directory: /local/UC-10/scaled_clouds_1cm/
json_path: /local/smart-tree/smart_tree/conf/trees_II/split.json
voxel_size: 0.01
input_features : ['xyz']
target_features: ['radius', 'medial_direction', 'class_l']


cmap:
  - [0.450, 0.325, 0.164] # Trunk
  - [0.541, 0.670, 0.164] # Foliage

# Training dataset...
train_dataset:
  _target_: smart_tree.dataset.dataset.Dataset
  mode: train
  directory: ${directory}
  json_path: ${json_path}
  cache: True
  augmentation:
    _target_: smart_tree.dataset.augmentations.AugmentationPipeline
    augmentations:
      - _target_: smart_tree.dataset.augmentations.Scale
        min_scale: 0.9
        max_scale: 1.1
      # - _target_:  smart_tree.dataset.augmentations.RandomFlips
      #   x_prob: 0.5
      #   y_prob: 0.5
      - _target_:  smart_tree.dataset.augmentations.RandomCubicCrop
        size: 4.0
      - _target_:  smart_tree.dataset.augmentations.RandomDropout
        probability: 0.1
      - _target_:  smart_tree.dataset.augmentations.RandomGaussianNoise
        mean : 0.0
        std : 0.5
        prob : 0.5
        magnitude : 0.02
      # - _target_:  smart_tree.dataset.augmentations.Dropout3D
      #   noise_scale: [0.5, 1.0]
      #   octaves: 6
      #   freq_multiplier: 1.2
        
      #   dropout: [0.0, 0.2]
      #   peturb: [0.1, 0.4]

      #   peturb_bias: 0.5  
      #   peturb_distance: [0.0, 0.006]
  
  transform:
    _target_ : smart_tree.model.pointnet.transform.split_cloud
    _partial_ : True


train_data_loader:
  _target_: torch.utils.data.DataLoader
  batch_size: ${batch_size}
  drop_last: False
  pin_memory: False
  num_workers: 0
  shuffle: False
  
  sampler:
    _target_: torch.utils.data.RandomSampler
    replacement: True
    num_samples: 256
    data_source: ${train_dataset}

  # collate_fn:
  #   _target_: smart_tree.model.sparse.util.batch_collate
  #   _partial_: True

  dataset: ${train_dataset}

# Val dataset
validation_dataset:
  _target_: smart_tree.dataset.dataset.Dataset
  mode: validation
  directory: ${directory}
  json_path: ${json_path}
  cache: True
  # transform:
  #   _target_ : smart_tree.model.sparse.transform.sparse_voxelize
  #   _partial_ : True
  #   input_features: ${input_features}
  #   target_features: ${target_features}
  #   voxel_size: ${voxel_size}
validation_data_loader:
  _target_: torch.utils.data.DataLoader
  batch_size: ${batch_size}
  drop_last: True
  pin_memory: False
  num_workers: 0
  shuffle: False
  # collate_fn:
  #   _target_: smart_tree.model.sparse.util.batch_collate
  #   _partial_: True

  dataset: ${validation_dataset}

# Test dataset
test_dataset:
  _target_: smart_tree.dataset.dataset.Dataset
  mode: test
  directory: ${directory}
  json_path: ${json_path}
  cache: True
  # transform:
  #   _target_ : smart_tree.model.sparse.transform.sparse_voxelize
  #   _partial_ : True
  #   input_features: ${input_features}
  #   target_features: ${target_features}
  #   voxel_size: ${voxel_size}
test_data_loader:
  _target_: torch.utils.data.DataLoader
  batch_size: ${batch_size}
  drop_last: True
  pin_memory: False
  num_workers: 0
  shuffle: False
  # collate_fn:
  #   _target_: smart_tree.model.sparse.util.batch_collate
  #   _partial_: True

  dataset: ${test_dataset}

model:
  _target_: smart_tree.model.pointnet.model.PointNet
  output_channels: 3


optimizer:
  _target_: torch.optim.Adam
  lr: ${lr}

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: "min"